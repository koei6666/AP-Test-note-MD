## プロセッサの高速化技術
　プロセッサの高速化には、CPUのクロックアップ、ハードディスクの読み込み効率向上などハードウェアのアプローチの他に、CPUの単位時間当たり処理量　#スループット の向上 、マルチCPUでの処理のアプローチがある。
　[[過去問#^3bba9b]]
　スループット向上に着目したパイプライン処理について下記で説明する。
　　#パイプライン処理 
　　パイプライン処理は、一つの命令を処理装置などでいくつかのステージに分けて、そして複数の命令を並列で処理する手法。
　　CPUは同時に一つの処理しかできないが、命令をステージに分け、ステージ毎にずらして実行していけば、1番の命令が演算処理を実施しているとき、2番目の命令が読み込みをし、3番目の命令がデコードされているように一つの命令が終了した後次の命令の前処理を待つことなく、各機構の並列処理が実現される。
　　パイプライン処理は各ステージが一定の時間で一斉に次のステージへ移転しないと効率が悪くなるので、各命令は定長である必要がある、そのため #RISC が使われている。
　　その上、パイプラインをさらに細分することによって高速化を図る #スーパーパイプライン　がある。
　　[[過去問#^073729]]
　　#パイプラインハザード
　　パイプライン処理によって、理論上ではステージの数の命令を同時に処理でき、高速化を期待できるが、実際運用上では、プログラムの設計により、先読みした命令が無駄になったり、処理の待ち合わせが発生したりすることで、パイプラインの乱れが発生する場合がある、このような場合はパイプラインハザードと呼ぶ。
　　#制御ハザード 
　　 #分岐ハザード
　　制御ハザードとは、プログラム内分岐が発生する場合、==命令を先読みしても、分岐の結果によって別の命令が実行されることがあり、先読みした命令が無効になるケースを制御ハザードと呼ぶ。==
　　制御ハザードを完全に回避すること（分岐処理をなくすこと）は不可能ので（IFの他に、FORやWHILEなども分岐処理に基づくので）、軽減するには、不要な分岐処理を減らす以外、以下の二つの手法がある。
　　　#投機実行
　　　分岐先の命令を予測し、先に読み込みをする、予測が当たった場合は処理速度の向上ができる。
　　　#遅延分岐
　　　分岐の内容とは関係なく、必ず実行される処理を分岐の前に順番を上げ、先に処理すること。
　　#データハザード 
　　データの依存関係により、後から来る命令が先頭命令のデータ書き込み完了するまで待機しなければいけないハザード。
　　#構造ハザード 
　　システム資源へ、プログラムのアクセスが集中し、競合が発生するハザード。
　　[[過去問#^073729]]

　#パイプライン処理効果
	　1つの命令を分割したステージ数を #パイプラインの深さ （D）と呼び、1つのステージを実行するに当たって必要な時間を #パイプラインピッチ （P）と呼ぶ。
	　Nこの名を例を実行するに必要な時間を以下の式で表現できる（パイプラインハザードを考慮しない）[[過去問#^60fbde]]
	　![[Pasted image 20231110121024.png]]
	　
$$(D+N-1)\times P$$
　　この公式では、処理時間に計算は:命令が順次に処理され、且つ、2番目以降の命令は前の命令が実行されている間に、順次解読と処理されるので、後ろ命令の完了は前命令より1パイプライン単位ずつ後ろにずれている。
　　そのため、最終的に処理した時間は、命令数(並行処理)、パイプラインの深さ(最後の、並行処理されない命令)、-1(最後命令と前命令の被るパイプライン)で計算される
　　例えば、パイプラインピッチ＝1ms,深さ3のパイプラインがパイプライン使用せずに3個の命令を実行するに必要な時間は
　　$$3\times 1 \times 3=9ms $$
　　それに対して、パイプラインを使用する場合の必要時間は以下の通り、約３０％の時間削減を実現できたとわかる。
$$
(3+4-1)\times 1=6ms
$$

　#スーパースカラ 
　　CPU内複数のパイプラインを使用することで、どうステージの命令を並行して実行することができるようにする技術。
　　ただし、スーパースカラを実現するには、命令間の依存関係を論理計算したり、複数の命令を同時にデコードすしたりし、 #オーバーヘッド が発生する場合がある。
　　スーパースカラがオーバーヘッドがかかるのは、以下のシチュエーションがある。
　　**命令スケジューリングのオーバーヘッド：**

　　　命令スケジューリングは、複数の命令を可能な限り効率的に並列化するために行われます。このプロセスでは、データ依存関係、リソース競合、分岐予測などを考慮する必要があります。これにより、プロセッサは追加のハードウェアリソースと時間を必要とするため、これがオーバーヘッドとなります。

　　**命令フェッチとデコードのオーバーヘッド：**

　　　スーパースカラプロセッサでは、複数の命令を同時にフェッチ（取得）およびデコード（解読）する必要があります。これには、高度なブランチ予測ロジックやより大きな命令キャッシュなど、追加のハードウェアリソースが必要となります。

　　**リソースの競合：**

　　　スーパースカラプロセッサでは、複数の命令が同時に実行されるため、異なる命令が同じプロセッサリソース（たとえば、レジスタや実行ユニット）を要求する可能性があります。これはリソースの競合を引き起こし、その結果としてパフォーマンスが低下する可能性があります。

　　**エネルギーと熱のオーバーヘッド：**

　　　命令を同時に多く実行するというスーパースカラの特性は、大量の電力を必要とします。これにより、プロセッサは大量の熱を発生し、冷却のための追加の手段が必要となります。
　　スーパースカラの過去問および運用ロジックを示す図：
　　[[過去問#^a00f2d]]
　　[[過去問#^0a5b01]]
#VLIW 
　スーパースカラは、命令の実行順番や依存関係などを、命令実行時判断し、優先順位を並び替えしている、それに対して、VLIW(Very Long Instrction Word)方式は、CPUがあらかじめ相関関係のない複数の命令を並べて一つの命令として実行させて効率化を図る手法、事前に相関関係と順番を決めているので、オーバーヘッドが発生しなくく、効率の向上を図れるが、以下詳細を書いているように、順番を組み替えて命令を実行しているので、コンパイラの設計が難しくなる。
　パイプラインの乱れを抑制するためには、複合命令を一定長にしている、命令の長さが足りないときは、NOP命令（No Operation命令）を組み合わせて規定の長さまで足している。
　#アウトオブオーダ実行
　VLIWのように、命令の順番を並び替えして、一番効率のいい順番で命令を実行する方式をアウトオブオーダ実行と呼ぶ、それに対して、順番通り命令を実行する方式を #インオーダ実行 と呼ばれる。
　整合性を確保するには #レジスタリネーミング　が使われる。 ^61f9a3
>[! レジスタリネーミング  ]
>アウトオブオーダ実行などを行うと、本来のプログラムとは異なる順番で命令を実行することがあります。この時使用されるレジスタでの入出力の整合性を保つために、コンパイラまたはCPUが使用するレジスタ名を変えて対応することです。


　VLIWアーキテクチャの主な利点は、ハードウェアの複雑さを大幅に削減できることです。これは、同時に実行される操作のスケジューリングをコンパイラに任せ、ハードウェアが命令間の依存関係を調整する必要がないからです。このため、VLIWアーキテクチャのCPUは、同じ計算能力を持つスーパースカラアーキテクチャのCPUよりもシンプルである可能性があります。
　
　しかし、このアプローチにはいくつかの欠点もあります。一つは、プログラムの性質によっては並列化が困難であるため、CPUの並列処理能力がフルに活用されない場合があることです。また、コンパイラの負担が増大するため、最適なスケジューリングを行うためには高度なコンパイラが必要となります。

　それに加え、VLIWプロセッサは、異なる命令セットやマイクロアーキテクチャの変更に対して非常に敏感です。これは、命令のグループ化とスケジューリングがプログラムのコンパイル時に行われるため、プロセッサの設計が変更されると、既存のソフトウェアは新しいアーキテクチャで最適に動作しない可能性があります。そのため、VLIWアーキテクチャはソフトウェアのバイナリ互換性の観点からは挑戦的です。

[[スーパースカラとVLIWの比較]]