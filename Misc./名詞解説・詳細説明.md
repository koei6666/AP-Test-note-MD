#コンジョイント分析 
	コンジョイント分析の例を説明します。 ^f4d8ff
	仮に、スマートフォンの開発を行う企業が、以下の3つの属性とそれぞれの属性に2つのレベルを持つ商品を調査したいとします。
	1. ブランド：A社、B社
	2. 価格：高額、手頃な価格
	3. カメラ性能：高解像度、光学ズーム機
	この場合、コンジョイント分析を行うために、被験者に異なる属性とレベルの組み合わせから選択してもらいます。例えば、以下のような選択肢を提示します。
	1. A社の高額なスマートフォン（高解像度カメラ）
	2. A社の手頃な価格のスマートフォン（光学ズーム機能）
	3. B社の高額なスマートフォン（光学ズーム機能）
	4. B社の手頃な価格のスマートフォン（高解像度カメラ）
	被験者は、このような選択肢から最も好ましいものを選びます。この選択行動のデータを集め、統計的な解析を行うことで、以下のような洞察を得ることができます。
	- ブランドの重要性：被験者が高額のスマートフォンを選択する傾向がある場合、ブランドが重要な要素となっていることが示唆されます。
	- 価格の影響：手頃な価格のスマートフォンが選択される割合が高い場合、価格が選択に与える影響が大きいことがわかります。
	- カメラ性能の優先順位：高解像度のカメラと光学ズーム機能のどちらが重要かを比較し、どの属性がより好まれるかを判断できます。
	これらの洞察は、商品開発やマーケティング戦略の決定に役立ちます。例えば、ブランドイメージの強化や価格戦略の見直し、カメラ性能の強調など、選好に合わせた施策を立案することが可能です。

#SCM(Supply Chain Management)
	購買，生産，販売及び物流の一連の業務を，企業間で全体最適の視点から見直し，納期短縮や在庫削減を図る。

#物流管理システム 
	資材の調達から生産，保管，販売に至るまでの物流全体を，費用対効果が最適になるように総合的に管理し，合理化する。

#EMS(Electronics Manufacturing Service)
	電子・電機メーカから，製品の設計や資材の調達，生産，物流，修理を一括して受託する。

#ACID 
 ACIDは、 #データベース管理システム （DBMS）におけるトランザクション処理の特性を表すために使用される用語です。ACIDは、以下の4つの特性を指します
	 1. 原子性（Atomicity）: トランザクションは、全ての操作が完了するか、または一切行われないかのいずれかの状態になることを保証します。トランザクション内の操作のいずれかが失敗した場合、すべての変更はロールバックされ、トランザクションが開始前の状態に戻されます。逆に、すべての操作が正常に完了した場合にのみ、変更は確定されます
	 2. 一貫性（Consistency）: トランザクションは、データベースがある事前定義の整合性制約を保持することを保証します。トランザクションの開始前と終了後に、データベースは一貫性のある状態を維持します。つまり、トランザクションの処理中にデータベースが矛盾した状態になることはありません。
	 3. 分離性（Isolation）: 同時に実行される複数のトランザクションが互いに干渉しないことを保証します。つまり、トランザクションは他のトランザクションの進行中の操作やデータに影響を与えずに実行されます。トランザクションが完了するまでの間、そのトランザクションの中間状態は他のトランザクションには見えません
	 4. 永続性（Durability）: トランザクションが正常に完了すると、その結果は永続的に保持されます。データベースシステムの障害や故障が発生しても、完了したトランザクションの結果は失われることはありません。結果はデータベースに永続的に保存され、復元された後も利用可能です。 ^5c5dcd

#網羅性のレベル には次のようなものあります。 ^63bc7d

#命令網羅(網羅性:低い↑) ^720be3

すべての命令を少なくとも１回は実行するテストケースを設計する。

#分岐網羅(判定条件網羅)

判定条件の真偽を少なくとも１回は実行するテストケースを設計する。

#条件網羅

判定条件が複数ある場合に、それぞれの条件が真・偽の場合を組み合わせたテストケースを設計する。

#判定条件・条件網羅

判定条件網羅と条件網羅を組み合わせてテストケースを設計する。

#複数条件網羅(***網羅性****:****高****↓)
判定条件のすべての可能な結果の組合せを網羅し、かつ、すべての命令を少なくとも１回は実行するようにテストケースを作成する。

#ページフォールト 
#LRU
	- ページ0  
	0は主記憶上にないためページフォールトが発生し、0がページインします。
	![[Pasted image 20230526215219.png]]
	-ページ1
	1は主記憶上にないためページフォールトが発生し、1がページインします。
	![[Pasted image 20230526215308.png]]
	-ページ2
	2は主記憶上にないためページフォールトが発生し、2がページインします。
	![[Pasted image 20230526215350.png]]
	-ページ3
	3は主記憶上にないためページフォールトが発生します。最終参照時刻が最も古いページ0がページアウトし、3がその位置にページインします。
	![[Pasted image 20230526215433.png]]
	-ページ4
	4は主記憶上にないためページフォールトが発生します。最終参照時刻が最も古いページ1がページアウトし、4がその位置にページインします。
	![[Pasted image 20230526215517.png]]
	-ページ0
	0は主記憶上にないためページフォールトが発生します。最終参照時刻が最も古いページ2がページアウトし、0がその位置にページインします。
	![[Pasted image 20230526215614.png]]
	-ページ4
	4は主記憶上にあるためページフォールトは発生しません。
	![[Pasted image 20230526215650.png]]
	 ^211f6a

#ダイレクトマップ
　ハッシュ演算などにより、主記憶のブロック番号からキャッシュメモリのブロック番号が一意に定まる方式。主記憶のブロックとキャッシュメモリのブロックが1対1で対応する
#フルアソシエイティブ
　主記憶のブロックをキャッシュメモリ上のどのブロックにも格納することができる方式
#セットアソシエイティブ
　キャッシュメモリのブロックを連続した一定数ごとにまとめた"セット"を用意し、主記憶のブロック番号から対応する"セット"が一意に定まり、そのセット内のブロックならどこでも格納できる方式。ダイレクトマップとフルアソシエイティブの中間的な存在で、現在ほぼすべてのCPUアーキテクチャで採用されている ^3435c0

#リポジトリ 
#チェックイン　#チェックアウト
　In the context of version control systems, such as Git, Subversion, or Mercurial, the terms "check in" and "check out" refer to the actions performed when working with repositories.
　1. Check out:
　Checking out a repository means creating a local working copy of the repository on your computer. This allows you to access and modify the files and directories within the repository. When you check out a repository, you typically specify a branch or a specific revision to work with. The checkout operation retrieves all the necessary files and history from the remote repository and sets up a local working environment.
　During the checkout process, the version control system creates a link between your local working copy and the remote repository. This link allows you to synchronize your changes with the repository later.
　2. Check in (also known as commit or push):
　Checking in refers to the act of saving your changes to the repository after you have made modifications to the files in your local working copy. It involves recording the changes you made, along with a descriptive message, and adding them to the repository's history.
　When you check in your changes, they become part of the repository's timeline, and other users can access and retrieve your modifications. Check-ins typically include metadata, such as the author's name, timestamp, and a log message explaining the purpose of the changes.
　Checking in your changes is essential for collaboration because it allows other team members to see and incorporate your modifications into their own working copies. It also provides a historical record of all the changes made to the codebase, making it easier to track and revert changes if necessary.
　In distributed version control systems like Git, the term "push" is often used instead of "check in" to describe the action of sending your committed changes from your local repository to a remote repository, making them available to others.
　To summarize, checking out creates a local working copy of the repository, allowing you to work on files, while checking in (or committing) saves your changes to the repository, making them available to others and creating a historical record of the changes. ^1396a9

#基数変換
　基数変換は、数値をある基数（進数）から別の基数（進数）に変換するプロセスです。通常、私たちが日常的に使用する数値システムは10進数システムですが、基数変換では10進数以外の基数に変換することもあります。

　一般的な基数には、2進数（バイナリ）、8進数、16進数などがあります。2進数は0と1の2つの数字だけを使用し、8進数は0から7までの数字を使用し、16進数は0から9までの数字とAからFまでのアルファベットを使用します。

　基数変換では、与えられた数値を元の基数の数値から別の基数の数値に変換します。これは、各桁の重み付けを変更することによって行われます。たとえば、10進数から2進数への変換では、数値を2で割りながら、剰余を桁ごとに取得していきます。最後に、取得した剰余を逆の順序で組み合わせて2進数の数値を得ることができます。
### 16進数から１０進数の変換方法

1. **各桁の値を特定**: 16進数の各桁の値を特定します。A～Fの文字は、10～15の数値に対応します。
2. **各桁の重み付け**: 16進数の右から左への各桁に、$16^n$ の重み付けをします。ここでnは右からの桁数で、最右の桁が0です。
3. **計算**: 各桁の値に対応する重み付けを掛けて、その合計を取ります。

**例: 16進数の2A3を10進数に変換する**

- 3 × $16^0$ = 3 × 1 = 3
- A (10) × $16^1$ = 10 × 16 = 160
- 2 × $16^2$ = 2 × 256 = 512
- 結果: 3 + 160 + 512 = 675

### 10進数から16進数への変換

10進数から16進数への変換は、以下の手順で行います。

1. **除算**: 10進数の数値を16で割ります。
2. **余りの取得**: 割り算の余りが16進数の最下位の桁になります。
3. **商の使用**: 商を新しい数値として使用し、再度16で割ります。
4. **繰り返し**: このプロセスを商が0になるまで繰り返します。
5. **16進数の対応**: 余りの数値が10以上の場合、対応する文字（A～F）を使用します。

**例: 10進数の254を16進数に変換する**

- 254 ÷ 16 = 15 ... 14 → E
- 15 ÷ 16 = 0 ... 15 → F
- 結果: FE

### 2進数から16進数への変換

2進数から16進数への変換は、特に直感的で簡単です。

1. **4ビットグループ化**: 2進数を右から左へ4ビットずつグループ化します。
2. **各グループの変換**: 各4ビットグループを対応する16進数の値に変換します。

**例: 2進数の11011110を16進数に変換する**

- 1101 → D
- 1110 → E
- 結果: DE

#OpenPGP 
　OpenPGP (Pretty Good Privacy) is an open standard for secure email communication and data encryption. It provides cryptographic privacy and authentication for data transmission, including email messages, files, and directories. OpenPGP is based on the earlier PGP protocol, which was created by Phil Zimmermann in 1991.

   OpenPGP uses a combination of symmetric-key and public-key cryptography to achieve its goals. It employs a public-key infrastructure where each user has a pair of cryptographic keys: a public key and a private key. The public key can be freely distributed and is used to encrypt data that only the corresponding private key can decrypt. Conversely, the private key is kept secret by the user and is used for decrypting received messages or signing messages to provide authentication and integrity.

#ダイレクト方式 
　ダイレクトマップ方式（直接マッピング方式）は、コンピュータのキャッシュメモリの一種です。キャッシュメモリは、主記憶装置（RAM）とCPUの間に配置され、データの高速なアクセスを提供するために使用されます。

　ダイレクトマップ方式では、キャッシュメモリは固定数のキャッシュライン（キャッシュエントリ）で構成されており、それぞれのキャッシュラインは主記憶装置の特定のブロックに対応しています。キャッシュラインは、キャッシュタグ、キャッシュデータ、および有効ビット（またはバリデーションビット）で構成されています。

　まず、CPUがデータを要求すると、キャッシュメモリはその要求がキャッシュ内に存在するかどうかを判断します。キャッシュメモリは要求されたデータのメモリアドレスを取り、そのアドレスの一部をキャッシュタグとして抽出します。キャッシュタグはキャッシュライン内のタグ部分と比較されます。

　もしキャッシュタグが一致し、有効ビットがセットされている場合、キャッシュメモリはキャッシュデータをCPUに返します。これはキャッシュヒットと呼ばれます。キャッシュヒットが発生した場合、データは高速にアクセスできるため、CPUの処理速度が向上します。

　一方、キャッシュタグが一致しない場合、または有効ビットがクリアされている場合、キャッシュメモリはキャッシュミスと判断します。キャッシュミスが発生した場合、キャッシュメモリはメインメモリから要求されたデータを取得し、キャッシュに格納します。その後、再度同じアドレスにアクセスがあった場合は、キャッシュヒットが発生します。

　==ダイレクトマップ方式では、主記憶装置の特定のブロックがキャッシュメモリ内の特定の位置に直接マップされます。このため、キャッシュラインの数が限られているため、同じ位置に複数のアドレスがマップされる可能性があります。これにより、キャッシュミスが頻繁に発生する場合、キャッシュの効率が低下する可能性があります。

　ダイレクトマップ方式は、実装が比較的簡単で効率的なキャッシュメモリアクセスを提供するため、多くのコンピュータシステムで使用されています。ただし、キャッシュの効率を向上させるために、より複雑な方式（例：セットアソシアティブ方式、フルアソシアティブ方式）も開発されています。

#メタデータ (MetaData)
　Metadata in a database refers to data that provides information about the structure, organization, and characteristics of the stored data. It describes the properties and attributes of the database objects, such as tables, columns, indexes, constraints, relationships, and more. Metadata acts as a form of "data about data" and helps in understanding, managing, and utilizing the database effectively. ^76248d

　Here are a few common examples of metadata in a database:

1. Table Metadata: It includes information about tables, such as their names, descriptions, creation dates, and the number of rows and columns they contain.

2. Column Metadata: This type of metadata describes the characteristics of individual columns within a table, including their names, data types, lengths, constraints, default values, and whether they are nullable or not.

3. Index Metadata: Index metadata provides information about the indexes defined on tables, such as their names, associated columns, uniqueness constraints, and index types (e.g., B-tree or hash indexes).

4. Relationship Metadata: In relational databases, metadata defines relationships between tables, such as primary key and foreign key constraints, which establish connections between related data.

5. View and Procedure Metadata: Metadata can describe views, which are virtual tables based on queries, and stored procedures, including their names, definitions, and associated parameters.

6. Security Metadata: This type of metadata specifies access control and permissions for database objects, defining who can read, modify, or delete specific data or execute certain operations.

　Metadata plays a crucial role in database management systems (DBMS) and helps in various aspects, including:

- Database administration: Metadata assists database administrators in understanding the database structure, optimizing performance, and managing security permissions.

- Data integration: Metadata aids in data integration by providing information on how different databases or systems are structured, facilitating data mapping and transformation.

- Data querying and analysis: Metadata enables users to understand the available data, the meaning of each column, and the relationships between tables, making it easier to formulate effective queries and perform analysis.

- Data governance and compliance: Metadata is essential for documenting data lineage, data quality, and compliance requirements, helping organizations ensure data accuracy, privacy, and regulatory compliance.

　Overall, metadata in databases is critical for effective database management, data understanding, and supporting various data-related processes and activities.

#スタック領域
　スタック領域は、プログラムが自動的に管理するメモリ領域です。これは関数呼び出しのコンテキスト（ローカル変数や戻りアドレスなど）を保存するために使用されます。スタックはその名の通り、"スタック"というデータ構造に従い、最後に入れたデータを最初に取り出す（Last In First Out: LIFO）という特性を持っています。スタック領域のメモリは関数が終了すると自動的に解放されますが、サイズは実行時には変更できないため、動的なメモリ管理には向いていません。
　一般にコールスタック・制御スタックと呼ばれている。
　サブルーチン終了後の戻りアドレスや局所変数などを保持する。 ^f52884

#ヒープ領域 
　一方、ヒープ領域はプログラムが直接制御するメモリ領域で、動的メモリ確保に使用されます。ヒープは任意のタイミングでデータを追加・削除することが可能で、大きさも動的に変更可能です。そのため、ランタイム中に大きさが変わるデータ構造や、生存期間が静的に決まらないオブジェクトに対して頻繁に使用されます。しかし、ヒープ領域のメモリ管理は手動で行わなければならず、不適切な管理はメモリリークを引き起こす可能性があるというデメリットがあります。
　2つのラベルを持つ双方向リストで構成されプログラム上から動的(任意)に確保できるメモリ領域。  
　動的にメモリ取得・解放を繰り返すことによりメモリ上にどこからも参照されない領域(ガベージ)が発生する。 ^1e3066

　それぞれの領域は役割が異なり、スタック領域は高速で管理が簡単ですが領域サイズが固定であり、ヒープ領域は動的で柔軟なメモリ管理が可能ですが手動での管理が必要となるため、その使用目的によって使い分けられます。

#モジュール接合度 
　ソフトウェア設計におけるモジュール間の接合度（カップリング）とは、あるモジュールが他のモジュールにどの程度依存しているかを示す指標です。低い接合度は、モジュールが独立して動作可能であることを意味し、これは一般的に望ましい特性とされています。 ^d60900

　以下に、一般的に認識されているモジュールの接合度のレベルを示します。ただし、具体的なレベルの数や定義は、文献により若干異なる場合があります。
![[モジュール分割の評価#^d70ff4]]

　これらの接合度のレベルは、ソフトウェア設計の品質を判断する重要な基準であり、一般的には低い接合度がソフトウェアの再利用性、保守性、理解性の観点から望ましいとされています。

#CAP定理 
　CAP定理とは、分散システムにおける以下の3つの特性に関する理論的な制約を示した定理です：
	1. **一貫性 (Consistency)**: すべてのノードが最新のデータを同時に見ることができます。一貫性が保たれると、分散システム内のすべての読み取り要求は、最新の書き込みに対応する値を返します。
	2. **可用性 (Availability)**: システムが常にすべての要求に対して応答を返すことができます。具体的には、すべての要求がタイムアウトやエラーなしに終了することを意味します。
	3. **分断耐性 (Partition Tolerance)**: システムがネットワークの分断（ネットワークの一部が利用できなくなる状態）を処理することができます。分断耐性があると、ネットワークの一部が利用できなくなってもシステムは動作し続けます。
　CAP定理は、任意の分散システムがこれら3つの特性を同時に保つことは不可能であると述べています。つまり、一度に2つの特性しか選択できないということです。この定理は、設計者がシステムの目的に最適なバランスを見つけるための指南となっています。例えば、一部のWebアプリケーションでは、分断耐性と可用性を優先し、一貫性を犠牲にするかもしれません。これは「結果整合性」と呼ばれるアプローチで、最終的にはデータが一貫した状態になることを保証しますが、その過程では一時的に古いデータをユーザーに表示することを許容します。 ^86d3cf
　
　一貫性と可用性を保証しようとすると必然的に単一のデータベースとなり、分断耐性がありません。また、一貫性と分断耐性を保証しようとすると、データベースの2相ロックや3相ロックが必要となり可用性が損なわれます（ロック中は利用できない）。そして、可用性と分断耐性を保証するシステムでは、ロックを掛けないので一貫性が損なわれます。
　![[Pasted image 20230529224529.png]] ^78ef68

#エクストリームプログラミング （Extreme Programming, XP）
　エクストリームプログラミング（Extreme Programming, XP）は、ソフトウェア開発の方法論の一つで、アジャイル開発手法の中でも最もよく知られているものの一つです。ケント・ベックが1990年代に開発しました。 ^e7cb6e

　エクストリームプログラミングは以下のような特徴を持っています：
	1. **イテレーション**: プロジェクトは小さなリリース（またはイテレーション）に分割され、各イテレーションは通常1-4週間の作業で完結します。各イテレーションの終わりには動作するソフトウェアが作成されます。
	2. **ペアプログラミング**: コードは常に2人の開発者によって作成されます。これによりコードの品質が向上し、知識の共有が促進されます。
	3. **ユニットテスト**: 開発者は自分たちが書いたすべてのコードに対してユニットテストを作成します。これによりバグが早期に発見され、コードの安全性が保たれます。
	4. **リファクタリング**: 開発者は定期的にコードを見直し、その構造や可読性を向上させます。
	5. **継続的インテグレーション**: コードの変更は頻繁に（数時間ごとに）メインのコードベースに統合（マージ）されます。
	6. **顧客の積極的な関与**: 顧客（またはその代理人）は開発チームの一部として働き、開発の進行状況についてのフィードバックを頻繁に提供します。

　エクストリームプログラミングの目的は、生産性と品質を向上させ、変更に対する柔軟性を提供することです。これにより、プロジェクトの要件が変わったとしても開発チームが素早く反応できます。

#White_box_test
#Black_box_test
#ほわいトボックステスト 
#ブラックボックステスト 
　White box testing and black box testing are two key approaches to testing software applications for bugs, errors, and other issues. Here's how they differ: ^b0cbd8

1. **White Box Testing**:
   - This testing is also known as clear box testing, open box testing, transparent box testing, or structural testing.
   - In white box testing, the internal workings of the application are fully known and accessible to the tester. The tester is aware of the internal structure and design of the software code.
   - This testing is primarily focused on the inner workings of an application. It checks how inputs are processed into outputs within a piece of software.
   - It requires specialized knowledge and the testers are usually developers or software engineers.
   - It helps to validate the code structure, data flow, conditional loops, and the internal logic of the software.
   - Example techniques include Statement Coverage, Decision Coverage, Path Coverage, and more.

2. **Black Box Testing**:
   - This testing is also known as behavioral testing or functional testing.
   - In black box testing, the internal structure/design/implementation of the item being tested is not known to the tester. Testers are only aware of what the software is supposed to do, not how it does it.
   - It checks the functionality of an application and validates whether the output is as expected, based on the given inputs.
   - It does not require any specialized knowledge, so the testers don't need to know the programming languages or techniques used to build the software.
   - It helps to validate the functional requirements of the software, such as how the software behaves or operates.
   - Example techniques include Equivalence Partitioning, Boundary Value Analysis, Decision Table Testing, and more.

　In sum, white box testing is about the internal logic and structure of the code, while black box testing is about the outputs based on the inputs and usage, without considering how the software produces those outputs. Both types of testing have their strengths and weaknesses, and are often used together for comprehensive software testing.

　ホワイトボックステストは、プログラムの内部構造に注目して行われるテストで、制御の流れの正当性を検証する目的で行われます。一方ブラックボックステストは、内部構造や論理構造には一切着目せずに入力値に対して正しい結果が得られるかどうかに着目したテスト行います。

　ホワイトボックステストのテストケース作成には、"命令網羅・判定条件網羅・条件網羅・判定条件/条件網羅・複数条件網羅"、ブラックボックステストのテストケース作成には、"同値分割・限界値分析・原因結果グラフ"が用いられます。

#逆数 
　逆数は、数の乗法における「逆元」を指します。具体的には、ある数aに対してその逆数は1/aとなります。そのため、ある数とその逆数を乗算すると結果は1になります。つまり、a * (1/a) = 1 です。 ^a1c499

　たとえば、5の逆数は1/5、0.2の逆数は1/0.2=5となります。一般に、0以外の任意の実数aに対して、その逆数は1/aとなります。

　ただし、0の逆数は定義されていません。なぜなら、0を乗じると結果が1になるような数は存在しないからです。したがって、逆数を考える際には、元の数が0でないことを確認する必要があります。

#オーバーレイ 
 必要な部分を補助記憶装置から読み込みながら動作する。主記憶領域の大きさに制限があるときに，有効な手法である。

#オーバーヘッド
　コンピュータサイエンスの文脈では、オーバーヘッドはシステムまたはプログラムが特定のタスクを遂行するために必要な追加のコンピューティングリソースを指します。これは、メモリ使用量、プロセッサ時間、ディスクスペース、ネットワーク帯域幅など、さまざまなリソースに関連している可能性があります。

　例えば、あるプログラムが大量のデータを処理するタスクを行う場合、そのデータを処理するために必要なリソースだけでなく、データを保存、取得、管理するための追加のリソースも必要になります。この追加のリソース使用がオーバーヘッドとなります。

#FromBinaryToHexadecimal
　Converting binary to hexadecimal is a straightforward process that involves grouping the binary digits and then translating each group into the corresponding hexadecimal digit. Here's a step-by-step breakdown: ^1f8009

　1. Group the binary digits into groups of four, starting from the rightmost (least significant) bit. If you don't have enough bits to make a group of four on the leftmost side, add zeroes to make up a full group.

　2. Convert each group of four binary digits to a decimal number. This is done by multiplying each bit by the corresponding power of two and summing the results:

　    For the rightmost group:
　    (1 * 2^0) + (2 * 2^1) + (4 * 2^2) + (8 * 2^3)

　    For the next group to the left:
　    (16 * 2^0) + (32 * 2^1) + (64 * 2^2) + (128 * 2^3)
  
　    And so on.

　3. Convert the decimal number from step 2 to its corresponding hexadecimal digit. Here are the decimal to hexadecimal correspondences for numbers 10 through 15:
   
   　　10 - A
   　　11 - B
   　　12 - C
   　　13 - D
   　　14 - E
   　　15 - F

　　For example, the binary number 1101 0010 would convert as follows:

　1. Group the binary digits into four: 1101 (the left group) and 0010 (the right group).
   
　2. Convert each group to decimal: 

   　　1101 = (1 * 2^3) + (1 * 2^2) + (0 * 2^1) + (1 * 2^0) = 8 + 4 + 0 + 1 = 13

   　　0010 = (0 * 2^3) + (0 * 2^2) + (1 * 2^1) + (0 * 2^0) = 0 + 0 + 2 + 0 = 2

　3. Convert these decimals to hexadecimal:

   　　13 is represented as 'D' in hexadecimal.
　　   2 remains '2' in hexadecimal.

　　So, the binary number 1101 0010 is represented as D2 in hexadecimal.

#同時マルチスレッディング
　同時マルチスレッディング（Simultaneous Multi-Threading: #SMT ）は、単一のプロセッサが複数のスレッドを同時に実行する能力のことを指します。この概念は、特にインテルのHyper-Threading技術として広く知られています。  ^5a41cb

　具体的な実例としては、仮想的な画像処理と文書作成の2つのタスクを想像してみてください。

　1. 画像処理タスク：これは大量の計算を必要とするタスクで、CPUの算術演算ユニットを大量に使用します。
　2. 文書作成タスク：これはユーザー入力（キーボードのタイプ）を待つなど、CPUのリソースを大量に使用しないタスクです。

　これらのタスクが単一のコア（非SMT）上で実行されているとき、CPUは、画像処理タスクがCPUリソースの大部分を占有するため、他のタスク（この場合、文書作成）が少々遅くなる可能性があります。

　しかし、SMT（例えば、Hyper-Threading）が有効なCPUでは、これらのタスクは異なるスレッドとして同時に実行されます。これにより、CPUは画像処理タスクが算術演算ユニットを使用している間に、別のスレッドで文書作成タスクを実行することができます。これにより、全体的なシステムパフォーマンスは向上し、ユーザーエクスペリエンスも改善します。

　注意すべきは、SMTは物理的なコア数を増やすわけではないため、コア数が倍増するわけではありません。しかし、SMTはCPUの使用効率を上げ、アイドル状態のリソースを有効活用することで、全体的なパフォーマンスを改善することができます。

#磁気ディスク のアクセス時間
　磁気ディスク装置のデータ読取りに要する時間は「$平均シーク時間＋平均回転待ち時間＋データ転送時間$」で求めます。 ^e3eb4e

　① 平均 #シーク時間 （ #シークタイム ）

　磁気ディスクのヘッドが、目的のデータが保存されている位置まで移動するのにかかる時間の平均

　②平均 #回転待ち時間 （ #サーチタイム ）

　ヘッドの移動が完了した後、読み出すレコードの先頭が磁気ヘッドの位置まで磁気ディスクが回転してくるのを待つ時間の平均。目的のデータがどの位置に存在するかはランダムなので、==ディスクが1回転するのにかかる時間の半分==が平均回転待ち時間となる

　③データ転送時間

　目的のデータを読み出すのに要する時間。
　問題によっては1トラックあたりの記憶容量というふうに記述する場合がある。
　その場合の計算方法は以下：
　　1トラックあたりの記憶容量=ヘッドが一周する場合書き込める容量
　　つまり以下の式で計算できる
　　RPUT=Rounds Per Unit Time
　　$$RPUT\times \left( \frac{Data}{DatePerTrack} \right)$$
　
#秒ナノ秒計算
　1s=$1\times 10^9 ns$
　When calculate second against nanosecond, especially in test, you can multiply s by 1000 and do the calculate then multiply the result by $10^6$.
　for example, if we want divide 1s by 80ns, we can do the calculate like below:
　$$1\times 10^3/80$$
　
#MIPS 
　MIPS（Million Instructions Per Second）とは、1秒間に実行できる命令の数を表す単位です。MIPS値が高いほど、パソコンの処理性能が高いことを意味します。
　MIPS値を計算するには、次の式を使用します。
　　MIPS = 1,000,000 / 平均命令実行時間
　平均命令実行時間は、1つの命令を実行するのにかかる時間です。平均命令実行時間は、CPUのクロック周波数と命令の複雑さによって異なります。 ^cc9978

　たとえば、クロック周波数が1GHzのCPUで、平均命令実行時間が2ナノ秒の命令を実行する場合、MIPS値は500MIPSになります。

#パリティ
#Parity
パリティとは、誤り検出に用いられる技術の一種で、2進数で表現されたデータの0または1の数が偶数個あるか、あるいは奇数個あるかを比較することである。

パリティを利用したチェックでは、データをあらかじめ一定の幅で区切り、その範囲における「1」のデータの偶奇（parity）を調べる。このとき、例えば「1」の数が奇数個であった場合には「1」を付け加えて偶数個にし、初めから偶数個あった場合には「0」を付け加えて偶数個の状態を維持する、という風にデータを整える。

データを受け取った側でも同様にして、偶奇がチェックされる。偶奇の異なる箇所が見つかった場合には、その箇所のデータが破損しているとみなしてデータの再送などが行われる。

パリティで付け加えられる「1」または「0」の1ビットのデータは、パリティビットと呼ばれている。また、パリティの技術を利用してエラーをチェックすることが特にパリティチェックと呼ばれている。

パリティは、誤り検出の手法としては代表的な方法であり、データをやり取りする様々な場面で利用されている。

#ストライピング
#Striping
**データを複数のハードディスクに分散して書き込むこと**。

#デイジーチェーン 
これは一連のデバイスが直列に接続されている形式で、最初のデバイスがホストコントローラに接続され、次のデバイスがその前のデバイスに接続され、という具体的な方法で接続が行われます。これにより、一連のデバイスが一つのチェーンまたはラインとして接続されます。

デイジーチェーン接続の一例としては、音楽とオーディオの世界でよく見られます。電子音楽機器の中には、MIDI (Musical Instrument Digital Interface) デバイスがあります。MIDIキーボード、ドラムマシン、シンセサイザーなどのデバイスは、MIDIケーブルを用いてデイジーチェーン接続を形成することが可能です。

この接続方法では、最初のデバイス（例えばMIDIコントローラ）が次のデバイス（例えばシンセサイザー）に直接接続され、その次のデバイス（例えばドラムマシン）がシンセサイザーに接続される、といった具体的な形で接続が行われます。これにより、MIDIコントローラからの信号がチェーンを通じて各デバイスに伝達され、一連の音楽機器が協調して動作します。

ただし、デイジーチェーン接続には一部の制限も存在します。例えば、MIDIのデイジーチェーン接続では、一つのチェーンにつき通常16台のデバイスまでが限度となっています。これを超えるとデータの遅延や損失が発生する可能性があります。また、各デバイスへの信号が連鎖的に伝わるため、チェーンの最後のデバイスへの信号伝達には時間がかかる場合があります。

"daisy chain"（デイジーチェーン）という表現は、元々は花、特にデイジー（ヒナギク）の花を使った花輪の作り方に由来します。デイジーの花の茎を互いに結んで連鎖的につなげ、花輪やネックレスを作るという方法があります。このように花を連鎖的につなげていく様子が、デイジーチェーン接続における機器のつなげ方に似ていることから、この名前がつけられました。

#マルチテナント
複数の利用者でサーバやデータベースを共有しながら，利用者ごとにデータベースの内容を明確に分離する技術である。

#リソースオンデマンド
利用者の要求に応じてリソースを動的に割り当てたり，不要になったリソースを回収して別の利用者のために移し替えたりする技術である。

#スワッピング
スワッピングは、なんらかの理由で主記憶上にあるプログラムが長時間待ち状態になっている場合に、そのプログラムを実行中のまま補助記憶上のスワップと呼ばれる場所に退避し、他のプログラムを主記憶にロードすることで中記憶の効率的な利用を行う手法です。

#RAD(Rapid Application Development)
GUIツールの利用によって比較的簡単にプログラムを作成でき，プロトタイピング開発やエンドユーザコンピューティングに適する。

$\Sigma$について

Σ記号の定義
　数学に用いられるΣ記号の定義は次のようになります。
　![[Pasted image 20230722124403.png]]

|   | |
|---|---|
|$a_{k}$|akは実際に繰り返す計算式|
|k=x|k=xの値は「kの初期値」|
|n|nの値は「kがこの値になるまで計算を繰り返す」|
![[Pasted image 20230722124601.png]]
例えばk=1,n=3,ak=10の条件の時は  
![[Pasted image 20230722124734.png]]

#TOC(Theory Of Constraints，制約条件の理論)
応答時間に最も影響があるボトルネックだけに着目して，適切な変更を行うことによって，そのボトルネックの影響を低減又は排除することである。

#ホットプラグ( #ホットスワップ)は、コンピュータの電源が入っている状態で周辺機器の脱着を行える仕組みです。手動でシステムの切り替えを行う場合には停止時間の短縮に寄与します。

#ストレージ統合
各サーバに存在する複数の磁気ディスクを，特定のサーバから利用できるようにして，資源の有効活用を図る。

#スーパーコンピューター
**スーパコンピュータ**(Super Computer)は、システムの中に数十個から数十万個のプロセッサを搭載することで、膨大な計算量を要する科学技術計算や3DCG計算などを短時間で高速に処理するためのコンピュータです。一般的に複雑であるベクトル演算や行列演算などを高速で処理するためのアレイプロセッサ(ベクトルプロセッサ)を持ち、高度なパイプライン制御で計算を同時並行的に行うことで高速処理を実現しています。  
天気予報、物理的シミュレーション、量子力学などの高度で膨大な量の演算が必要となる分野で使用されています。
現在のスーパコンピュータの設計では、処理ビット数を増加させるのではなく多数のCPUを並列につなぐことで処理速度を高速化しています。(256ビットCPUが1つと64ビットCPUが4つは同等の性能となります) ^986a70

#2相コミットメント機能
2相コミットメントは、コミットを2つの段階に分けて行うことで、分散データベース環境におけるトランザクションの原子性・一貫性を保証する手法です。

#グループコミットメント機能
グループコミットメントは、ディスクに対する書込み性能を向上するために、複数のトランザクションのコミット(ログ)をまとめてディスクに書き出す仕組みです。

#サーバプロセスのマルチスレッド機能
マルチスレッドは、1つのプロセス内に同時並行的かつ非同期で実行する単位を複数作ることで、処理を高速に実行する仕組みです。

#スレーブシステム
スレーブシステムは、1台のコンピュータから1台または複数台のコンピュータの制御を行うシステムです。制御する側をマスター、制御される側をスレーブという。

#非対称型マルチプロセッサシステム
OSを実行するプロセッサ，アプリケーションを実行するプロセッサというように，それぞれの役割が決定されている複数のプロセッサによって処理を分散する方式である。
カーネルプロセスとユーザプロセスを区別せずに，同等な複数のプロセッサに処理を分散する方式である。

#マルチスレッド
プロセッサ上でスレッド(プログラムの実行単位)レベルの並列化を実現し，プロセッサの利用効率を高める方式である

#デュアルブート
![[Pasted image 20230725205317.png]]

#タンデムシステム(tandem system)

複数のCPUを直列につなぎ、負荷分散するシステム構成。

#ロードシェアシステム(load share system)

２つ以上の複数の処理系をもち、ロードバランサなどを用いて各処理系に負荷を分散させることで処理効率や信頼性の向上を図るシステム構成。

#デュプレックスシステム(duplex system)

主系と待機系からなる２系列の処理システム構成。通常時は主系でオンライン処理、待機系でバッチ処理を行うが、主系の障害発生には、主系で行っていたオンライン処理を待機系に引き継ぎ処理を継続する。

#パーティショニング 
物理サーバのリソース(CPU，メモリなど)をブロック単位に物理的に分割し，あるブロックの障害が他のブロックに影響しないようにするので，障害時に業務の停止が許容できない場合に有効である。

#フォールダウン
フォールダウンは、モデムや無線LANにおいて通信が失敗したときにその速度を一段階ずつ下げて再処理することで通信の安定化を図る機能です。

#ハートビートパケット
#ヘルスチェック方式
ホットスタンバイのように両方のサーバが起動状態である冗長構成の場合は、障害発生時に即座に切替えができるようにサーバ同士が定期的に情報交換を行い、サーバダウンを自律的に検出するようになっています。確認方法としては、現用系のサーバが自らが正常に稼働していることを外部に知らせる「ハートビートパケット」や、待機系のサーバから現用系にパケット(ping,TCP,HTTPなど)を送り、適切な応答が得られるかで判断を行う「ヘルスチェック方式」などがあります。  
待機系は、ハートビートパケットが一定時間以上途切れた時やヘルスチェックでの異常を検知すると現用系で障害が発生したと判断します。そして自らが現用系となり処理を引き継ぐ仕組みになっています。 ^539e53

#シストリックアレイ
シストリックアレイは、多数のプロセッサとバッファの組をマトリクス上に結合して構築される並列計算機のアーキテクチャです。個々のプロセッサの演算結果をレジスタに書き戻さず、次の演算の入力として隣のプロセッサへそのまま渡すことで、シンプルな回路設計、高い電力効率、高い演算性能を実現します。


#デフラグソフト
デフラグソフト（デフラグメントソフトウェア、またはディスクデフラグメンタ）は、コンピュータのハードドライブまたはストレージデバイス上のファイルの断片化を解消するためのツールです。

断片化とは、ファイルがディスク上の複数の場所に分散して格納される現象を指します。これは時間とともにファイルが作成、削除、変更されると自然に起こります。断片化が進行すると、ファイルへのアクセス時間が増加し、システムのパフォーマンスが低下する可能性があります。

デフラグソフトは、これらの断片化されたファイルを再配置して、連続したディスク領域にまとめます。これにより、ファイルへのアクセス速度が向上し、システムのパフォーマンスが改善される可能性があります。

以下に、いくつかの主なデフラグソフトの例を挙げます。

1. Windowsのデフラグツール：Microsoft Windowsには組み込みのデフラグツールがあり、これを使用してディスクのデフラグメンテーションを行うことができます。

2. Defraggler：Piriformが開発した無料のデフラグツールで、個々のファイルまたはディスク全体のデフラグメンテーションを行うことができます。

3. O&O Defrag：O&O Softwareが開発した商用のデフラグツールで、さまざまなオプションと機能を提供しています。

ただし、SSD（Solid State Drive）を使用している場合は、デフラグメンテーションは通常不要であり、むしろSSDの寿命を短くする可能性があります。SSDは物理的なディスクヘッドを持たず、データの読み取り速度はデータの物理的な位置に依存しないため、デフラグメンテーションの恩恵を受けることはありません。また、SSDは書き込み回数に制限があるため、デフラグ操作はその寿命を縮める可能性があります。


- #Docker  
    **Docker**は、コンテナ型仮想化の環境で、アプリケーションを実行するための独立した環境を提供するOSSです。
- #KVM  
    KVM(Kernel-based Virtual Machine)は、Linuxカーネルが提供する仮想化ソフトウェアです。OSSですがハイパーバイザー型なので不適切です。
- #QEMU  
    QEMU(Quick Emulator)は、OSSの仮想化ソフトウェアですが、ホストOS型なので誤りです。
- #Xen  
    Xenは、OSSの仮想化ソフトウェアですが、ハイパーバイザー型なので誤りです。

#BIND
　バインドと読みます。  
　インターネットの世界で最も使われているDNSサーバです。

#Postfix
　ポストフィックスと読みます。  
　フリーソフトでOSSのメール転送エージェント(MTA)です。

#RDA (Remote Database Access)は、遠隔地のデータベースを操作するためのプロトコルで、ANSI/ISO/IEC 9579-1，9579-2として1993年に国際規格化されています。  
RDAにはクライアントから遠隔地のデータベースにSQL文を転送し、処理結果を返すデータベース操作の仕組みのほか、アソシエーション管理、資源ハンドリング、トランザクション管理などの機能が規定されています。

#CORBA  
    Common Object Request Broker Architectureの略。オブジェクト指向技術標準化団体(OMG)がまとめたオブジェクト指向による分散処理環境を実現するための国際標準仕様です。
#DDL  
    Data Definition Languageの略。SQL言語のうちデータベースの構造や構成を定義する命令群です。


