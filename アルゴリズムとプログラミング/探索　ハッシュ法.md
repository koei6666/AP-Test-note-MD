#ハッシュ法
ハッシュ法は検索値のキーにより、その検索値のアドレスを直接アクセス方法。
==一意探索に優れているが、連続したデータの探索には向いてない。==
格納場所を算出する関数をハッシュ関数、ハッシュ関数より求められるキーはハッシュ値と言い。
[[キャッシュメモリの割付方式#^21e59e|ハッシュ法を利用したダイレクマップ割付法]]
ハッシュ値は有限に対し、検索値は無限にあるので、二つ以上の検索値は必ず異なりハッシュ値が付与されるという理想状態ではハッシュ検索はO(1)の早いスピードで実行できる。複数の検索値に同じハッシュ値が付与されるのは　#衝突　あるいは #シノニム発生　と言う。
衝突対策として、  #チェーン法　#Chaining と #オープンアドレス法 #Open-addressing がある、これらの対策の実装方法によってはO(n)まで計算量が昇ることがある。

ハッシュ探索は非常に効率的な探索方法ですが、すべてのデータや問題設定に適しているわけではありません。以下にハッシュ探索が不適切となる一部のシナリオを挙げます：

1. **順序情報が重要な場合**: ハッシュ表はデータを格納する順序を保持しません。したがって、順序情報が重要な場合（例えば、データがソートされていて範囲検索や最大/最小値を効率的に見つける必要がある場合）は、ハッシュ探索は適していません。

2. **頻繁にデータが更新される場合**: ハッシュ表では、新しいデータの追加や既存データの削除が行われるたびにハッシュ関数の再計算が必要です。これは、特に大量のデータが頻繁に追加/削除される場合、パフォーマンスのボトルネックになる可能性があります。

3. **ハッシュ関数の選択が難しい場合**: ハッシュ関数の選択は、ハッシュ表のパフォーマンスに大きく影響します。特定のデータセットに対して適切なハッシュ関数を設計するのは難しい場合があります。

4. **メモリ制限が厳しい場合**: ハッシュ表は通常、単純な配列やリンクリストに比べてより多くのメモリを必要とします。これは、ハッシュ表が空のスロットを持つこと（ロードファクターと呼ばれます）と、ハッシュ衝突を避けるために追加のデータ構造を必要とすることによります。したがって、メモリが厳しく制限されている場合、ハッシュ表は適切な選択肢ではないかもしれません。

したがって、使用するデータ構造を選択する際は、具体的な要件とトレードオフを考慮することが重要です。

Chainingは各ハッシュ値をLinked listのheadとし、重複の検索値が発生した場合は、既存値に連結する方法で格納する。データが平均分布した場合は、O(1),すべてのデータが一つのハッシュ値にリンクした場合は最悪ケースO(n)の計算量が発生する。
チェーン法の計算量は全データ数N、ハッシュテーブルの大きさMと比例している、Nが少なければ、その逆にMが大きければ、一つハッシュ値に付属する値は少なくなり、計算量が少なくなる、逆にNが大きく、Mが小さければ計算量が多くなる。


オープンアドレス法は、もしハッシュ値はすでに使用されている場合は、ハッシュ値+1で次のハッシュ値を探し、使用されてないハッシュ値まで検索する。

オープンアドレス法は、ハッシュ関数の仕組みにより、多くの値が同じハッシュ値に集中し、値がハッシュ値＋１の形で連続して配属される現象をクラスタリング ( #Clustering ）と呼ぶ。クラスタリングしている値では、例えば間の値だけを削除した場合、検索時では削除された値より後ろの値が検索できなくなる。
この現象を避けるには、削除した値のハッシュ値にTombstone、すなわち削除した目印を残すことや、値を削除したら、後ろの値を一つずつ繰上げして詰めることが必要。

> [!Will open addressing loop forever if all hash is filled?]
> Open addressing is a collision resolution technique in hash tables that finds another spot in the table when a collision occurs. Some common open addressing strategies are linear probing, quadratic probing, and double hashing.
>Your question seems to assume a situation where a hash table is completely filled and you're trying to insert a new element. In this case, you're correct. If the hash table is full and you're using open addressing to find a spot for a new element, the algorithm will keep looping over the table indefinitely, unable to find a spot.
>This situation, however, should be avoided through good hash table management. Typically, a load factor is maintained for a hash table, which is the ratio of the number of elements in the table to the size of the table. When the load factor exceeds a certain threshold (like 0.7 or 0.8), the table is resized - usually doubled in size. This process is called rehashing, and it helps maintain the efficiency of operations on the hash table.
>So, in practice, you should never reach a state where the hash table is completely filled and new elements cannot be inserted. By monitoring the load factor and resizing the table as necessary, you can ensure that there is always space available for new elements. This helps keep the time complexity of search, insert, and delete operations close to O(1) on average.

